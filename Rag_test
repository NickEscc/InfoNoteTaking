# Imports
from pymongo import MongoClient
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import MongoDBAtlasVectorSearch
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain_openai.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os
import key_param
import tkinter as tk
from tkinter import filedialog, messagebox

# Environment Setup
os.environ['OPENAI_API_KEY'] = key_param.openai_api_key

# MongoDB Connection
def setup_mongo_connection():
    """Setup MongoDB connection and return the collection."""
    client = MongoClient(key_param.MONGO_URI)
    try:
        client.admin.command('ping')
        print("Pinged your deployment. You successfully connected to MongoDB!")
    except Exception as e:
        print(e)
    db = client['RagProject']
    return db['Notes']

collection = setup_mongo_connection()

# Vector Store Configuration
ATLAS_VECTOR_SEARCH_INDEX_NAME = "vector_index"
embeddings = OpenAIEmbeddings(openai_api_key=key_param.openai_api_key, disallowed_special=())
vector_search = MongoDBAtlasVectorSearch(
    collection=collection,
    embedding=embeddings,
    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME
)
retriever = vector_search.as_retriever(search_type="similarity", search_kwargs={"k": 1})

# Prompt and Model Setup
template = """Answer the question: {question} based only on the following context:
context: {context}
If the context does not contain the answer, respond with "I don't know based on the provided context."
"""
prompt = PromptTemplate.from_template(template=template, input_varaibles=["context", "question"])
output_parser = StrOutputParser()
model = ChatOpenAI(openai_api_key=key_param.openai_api_key, model_name='gpt-3.5-turbo', temperature=0)

retrieval_chain = (
    {"context": retriever | (lambda docs: "\n\n".join(doc.page_content for doc in docs)), "question": RunnablePassthrough()}
    | prompt
    | model
    | output_parser
)

# Data Import Functions
def import_individual_pdf(file_path):
    """Import and process an individual PDF file."""
    if not file_path.endswith(".pdf"):
        print("Error: Only PDF files are supported.")
        return
    if is_data_already_uploaded(file_path):
        print("This PDF has already been uploaded.")
        return
    loader = PyPDFLoader(file_path)
    data = loader.load()
    print(f"Loaded {len(data)} documents from {file_path}.")
    process_and_store_data(data)

def import_pdf_batch(folder_path):
    """Import and process a batch of PDF files from a folder."""
    if not os.path.isdir(folder_path):
        print("Error: Invalid folder path.")
        return
    for file_name in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file_name)
        if file_path.endswith(".pdf"):
            import_individual_pdf(file_path)

def import_plain_text():
    """Import and process plain text input from the user."""
    content = input("Enter the plain text content: ").strip()
    if not content:
        print("Error: No text provided.")
        return
    data = [{"page_content": content, "metadata": {"source": "user_input"}}]
    print("Loaded plain text data from user input.")
    process_and_store_data(data)

def is_data_already_uploaded(file_path):
    """Check if the data from the file has already been uploaded."""
    file_hash = hash(open(file_path, "rb").read())
    existing_hashes = collection.distinct("metadata.file_hash")
    return file_hash in existing_hashes

def process_and_store_data(data):
    """Process and store data in the vector store."""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)
    chunks = text_splitter.split_documents(data)
    MongoDBAtlasVectorSearch.from_documents(
        documents=chunks,
        embedding=embeddings,
        collection=collection,
        index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME
    )
    print("Data processed and stored successfully.")

# GUI Functions
def import_individual_pdf_gui():
    """Open a file dialog to select a single PDF file and process it."""
    file_path = filedialog.askopenfilename(filetypes=[("PDF files", "*.pdf")])
    if file_path:
        import_individual_pdf(file_path)
        messagebox.showinfo("Success", "PDF imported successfully!")

def import_pdf_batch_gui():
    """Open a folder dialog to select a folder containing PDF files and process them."""
    folder_path = filedialog.askdirectory()
    if folder_path:
        import_pdf_batch(folder_path)
        messagebox.showinfo("Success", "Batch of PDFs imported successfully!")

def import_plain_text_gui():
    """Open a dialog to input plain text and process it."""
    text_input_window = tk.Toplevel()
    text_input_window.title("Enter Plain Text")
    text_input_window.geometry("400x300")

    text_label = tk.Label(text_input_window, text="Enter your text below:")
    text_label.pack(pady=10)

    text_box = tk.Text(text_input_window, wrap=tk.WORD, height=10)
    text_box.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)

    def submit_text():
        content = text_box.get("1.0", tk.END).strip()
        if content:
            data = [{"page_content": content, "metadata": {"source": "user_input"}}]
            process_and_store_data(data)
            messagebox.showinfo("Success", "Plain text imported successfully!")
            text_input_window.destroy()
        else:
            messagebox.showerror("Error", "No text provided.")

    submit_button = tk.Button(text_input_window, text="Submit", command=submit_text)
    submit_button.pack(pady=10)

def ask_question_gui():
    """Open a dialog to input a question and display the response."""
    question_window = tk.Toplevel()
    question_window.title("Ask a Question")
    question_window.geometry("400x200")

    question_label = tk.Label(question_window, text="Enter your question below:")
    question_label.pack(pady=10)

    question_entry = tk.Entry(question_window, width=50)
    question_entry.pack(pady=10)

    def submit_question():
        question = question_entry.get().strip()
        if question:
            response = retrieval_chain.invoke(question)
            messagebox.showinfo("Response", f"Response: {response}")
            question_window.destroy()
        else:
            messagebox.showerror("Error", "No question provided.")

    submit_button = tk.Button(question_window, text="Submit", command=submit_question)
    submit_button.pack(pady=10)

# Main GUI
def main_gui():
    """Main GUI interface for the user."""
    root = tk.Tk()
    root.title("RAG Notes Interface")
    root.geometry("400x300")

    title_label = tk.Label(root, text="RAG Notes Interface", font=("Arial", 16))
    title_label.pack(pady=20)

    import_pdf_button = tk.Button(root, text="Import Individual PDF", command=import_individual_pdf_gui, width=30)
    import_pdf_button.pack(pady=5)

    import_batch_button = tk.Button(root, text="Import Batch of PDFs", command=import_pdf_batch_gui, width=30)
    import_batch_button.pack(pady=5)

    import_text_button = tk.Button(root, text="Import Plain Text", command=import_plain_text_gui, width=30)
    import_text_button.pack(pady=5)

    ask_question_button = tk.Button(root, text="Ask a Question", command=ask_question_gui, width=30)
    ask_question_button.pack(pady=5)

    exit_button = tk.Button(root, text="Exit", command=root.quit, width=30)
    exit_button.pack(pady=20)

    root.mainloop()

if __name__ == "__main__":
    main_gui()